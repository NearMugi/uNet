{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KerasでU-Net  \n",
    "[U-NetでPascal VOC 2012の画像をSemantic Segmentationする (TensorFlow)](https://qiita.com/tktktks10/items/0f551aea27d2f62ef708)\n",
    "Kerasバージョンに変更する\n",
    "\n",
    "* keras == 2.0.4  \n",
    "* tensorflow == 1.15.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, ZeroPadding2D, Conv2DTranspose\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import LeakyReLU, BatchNormalization, Activation, Dropout\n",
    "\n",
    "class UNet(object):\n",
    "    def __init__(self, input_channel_count, output_channel_count, first_layer_filter_count):\n",
    "        self.INPUT_IMAGE_SIZE = 256\n",
    "        self.CONCATENATE_AXIS = -1\n",
    "        self.CONV_FILTER_SIZE = 4\n",
    "        self.CONV_STRIDE = 2\n",
    "        self.CONV_PADDING = (1, 1)\n",
    "        self.DECONV_FILTER_SIZE = 2\n",
    "        self.DECONV_STRIDE = 2\n",
    "\n",
    "        # (256 x 256 x input_channel_count)\n",
    "        inputs = Input((self.INPUT_IMAGE_SIZE, self.INPUT_IMAGE_SIZE, input_channel_count))\n",
    "\n",
    "        # エンコーダーの作成\n",
    "        # (128 x 128 x N)\n",
    "        enc1 = ZeroPadding2D(self.CONV_PADDING)(inputs)\n",
    "        enc1 = Conv2D(first_layer_filter_count, self.CONV_FILTER_SIZE, strides=self.CONV_STRIDE)(enc1)\n",
    "\n",
    "        # (64 x 64 x 2N)\n",
    "        filter_count = first_layer_filter_count*2\n",
    "        enc2 = self._add_encoding_layer(filter_count, enc1)\n",
    "\n",
    "        # (32 x 32 x 4N)\n",
    "        filter_count = first_layer_filter_count*4\n",
    "        enc3 = self._add_encoding_layer(filter_count, enc2)\n",
    "\n",
    "        # (16 x 16 x 8N)\n",
    "        filter_count = first_layer_filter_count*8\n",
    "        enc4 = self._add_encoding_layer(filter_count, enc3)\n",
    "\n",
    "        # (8 x 8 x 8N)\n",
    "        enc5 = self._add_encoding_layer(filter_count, enc4)\n",
    "\n",
    "        # (4 x 4 x 8N)\n",
    "        enc6 = self._add_encoding_layer(filter_count, enc5)\n",
    "\n",
    "        # (2 x 2 x 8N)\n",
    "        enc7 = self._add_encoding_layer(filter_count, enc6)\n",
    "\n",
    "        # (1 x 1 x 8N)\n",
    "        enc8 = self._add_encoding_layer(filter_count, enc7)\n",
    "\n",
    "        # デコーダーの作成\n",
    "        # (2 x 2 x 8N)\n",
    "        dec1 = self._add_decoding_layer(filter_count, True, enc8)\n",
    "        dec1 = concatenate([dec1, enc7], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (4 x 4 x 8N)\n",
    "        dec2 = self._add_decoding_layer(filter_count, True, dec1)\n",
    "        dec2 = concatenate([dec2, enc6], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (8 x 8 x 8N)\n",
    "        dec3 = self._add_decoding_layer(filter_count, True, dec2)\n",
    "        dec3 = concatenate([dec3, enc5], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (16 x 16 x 8N)\n",
    "        dec4 = self._add_decoding_layer(filter_count, False, dec3)\n",
    "        dec4 = concatenate([dec4, enc4], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (32 x 32 x 4N)\n",
    "        filter_count = first_layer_filter_count*4\n",
    "        dec5 = self._add_decoding_layer(filter_count, False, dec4)\n",
    "        dec5 = concatenate([dec5, enc3], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (64 x 64 x 2N)\n",
    "        filter_count = first_layer_filter_count*2\n",
    "        dec6 = self._add_decoding_layer(filter_count, False, dec5)\n",
    "        dec6 = concatenate([dec6, enc2], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (128 x 128 x N)\n",
    "        filter_count = first_layer_filter_count\n",
    "        dec7 = self._add_decoding_layer(filter_count, False, dec6)\n",
    "        dec7 = concatenate([dec7, enc1], axis=self.CONCATENATE_AXIS)\n",
    "\n",
    "        # (256 x 256 x output_channel_count)\n",
    "        dec8 = Activation(activation='relu')(dec7)\n",
    "        dec8 = Conv2DTranspose(output_channel_count, self.DECONV_FILTER_SIZE, strides=self.DECONV_STRIDE)(dec8)\n",
    "        dec8 = Activation(activation='sigmoid')(dec8)\n",
    "\n",
    "        self.UNET = Model(input=inputs, output=dec8)\n",
    "\n",
    "    def _add_encoding_layer(self, filter_count, sequence):\n",
    "        new_sequence = LeakyReLU(0.2)(sequence)\n",
    "        new_sequence = ZeroPadding2D(self.CONV_PADDING)(new_sequence)\n",
    "        new_sequence = Conv2D(filter_count, self.CONV_FILTER_SIZE, strides=self.CONV_STRIDE)(new_sequence)\n",
    "        new_sequence = BatchNormalization()(new_sequence)\n",
    "        return new_sequence\n",
    "\n",
    "    def _add_decoding_layer(self, filter_count, add_drop_layer, sequence):\n",
    "        new_sequence = Activation(activation='relu')(sequence)\n",
    "        new_sequence = Conv2DTranspose(filter_count, self.DECONV_FILTER_SIZE, strides=self.DECONV_STRIDE,\n",
    "                                       kernel_initializer='he_uniform')(new_sequence)\n",
    "        new_sequence = BatchNormalization()(new_sequence)\n",
    "        if add_drop_layer:\n",
    "            new_sequence = Dropout(0.5)(new_sequence)\n",
    "        return new_sequence\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.UNET\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理関連の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 値を-1から1に正規化する関数\n",
    "def normalize_x(image):\n",
    "    image = image/127.5 - 1\n",
    "    return image\n",
    "\n",
    "\n",
    "# 値を0から1に正規化する関数\n",
    "def normalize_y(image):\n",
    "    image = image/255\n",
    "    return image\n",
    "\n",
    "\n",
    "# 値を0から255に戻す関数\n",
    "def denormalize_y(image):\n",
    "    image = image*255\n",
    "    return image\n",
    "\n",
    "\n",
    "# インプット画像を読み込む関数\n",
    "def load_X(folder_path):\n",
    "    import os, cv2\n",
    "\n",
    "    image_files = os.listdir(folder_path)\n",
    "    image_files.sort()\n",
    "    images = np.zeros((len(image_files), IMAGE_SIZE, IMAGE_SIZE, 3), np.float32)\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        images[i] = normalize_x(image)\n",
    "    return images, image_files\n",
    "\n",
    "\n",
    "# ラベル画像を読み込む関数\n",
    "def load_Y(folder_path):\n",
    "    import os, cv2\n",
    "\n",
    "    image_files = os.listdir(folder_path)\n",
    "    image_files.sort()\n",
    "    images = np.zeros((len(image_files), IMAGE_SIZE, IMAGE_SIZE, 1), np.float32)\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image = image[:, :, np.newaxis]\n",
    "        images[i] = normalize_y(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メイン処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "230/230 [==============================] - 12s 52ms/step - loss: 0.6241 - dice_coef: 0.3759\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.5686 - dice_coef: 0.4314\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.5293 - dice_coef: 0.4707\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.4919 - dice_coef: 0.5081\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.4655 - dice_coef: 0.5345\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.4443 - dice_coef: 0.5557\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.4176 - dice_coef: 0.5824\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.4056 - dice_coef: 0.5944\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.4002 - dice_coef: 0.5998\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3803 - dice_coef: 0.6197\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3662 - dice_coef: 0.6338\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3571 - dice_coef: 0.6429\n",
      "Epoch 13/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3287 - dice_coef: 0.6713\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3254 - dice_coef: 0.6746\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3058 - dice_coef: 0.6942\n",
      "Epoch 16/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.3112 - dice_coef: 0.6888\n",
      "Epoch 17/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2772 - dice_coef: 0.7228\n",
      "Epoch 18/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2579 - dice_coef: 0.7421\n",
      "Epoch 19/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2714 - dice_coef: 0.7286\n",
      "Epoch 20/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2608 - dice_coef: 0.7392\n",
      "Epoch 21/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2405 - dice_coef: 0.7595\n",
      "Epoch 22/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2230 - dice_coef: 0.7770\n",
      "Epoch 23/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2176 - dice_coef: 0.7824\n",
      "Epoch 24/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2216 - dice_coef: 0.7784\n",
      "Epoch 25/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.2053 - dice_coef: 0.7947\n",
      "Epoch 26/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1900 - dice_coef: 0.8100\n",
      "Epoch 27/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1915 - dice_coef: 0.8085\n",
      "Epoch 28/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1799 - dice_coef: 0.8201\n",
      "Epoch 29/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1793 - dice_coef: 0.8207\n",
      "Epoch 30/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1626 - dice_coef: 0.8374\n",
      "Epoch 31/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1567 - dice_coef: 0.8433\n",
      "Epoch 32/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1662 - dice_coef: 0.8338\n",
      "Epoch 33/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1658 - dice_coef: 0.8342\n",
      "Epoch 34/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1549 - dice_coef: 0.8451\n",
      "Epoch 35/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1441 - dice_coef: 0.8559\n",
      "Epoch 36/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1581 - dice_coef: 0.8419\n",
      "Epoch 37/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1616 - dice_coef: 0.8384\n",
      "Epoch 38/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1391 - dice_coef: 0.8609\n",
      "Epoch 39/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1289 - dice_coef: 0.8711\n",
      "Epoch 40/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1321 - dice_coef: 0.8679\n",
      "Epoch 41/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1346 - dice_coef: 0.8654\n",
      "Epoch 42/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1318 - dice_coef: 0.8682\n",
      "Epoch 43/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1236 - dice_coef: 0.8764\n",
      "Epoch 44/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1210 - dice_coef: 0.8790\n",
      "Epoch 45/100\n",
      "230/230 [==============================] - 5s 22ms/step - loss: 0.1268 - dice_coef: 0.8732\n",
      "Epoch 46/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1075 - dice_coef: 0.8925\n",
      "Epoch 47/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1058 - dice_coef: 0.8942\n",
      "Epoch 48/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.1090 - dice_coef: 0.8910\n",
      "Epoch 49/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1196 - dice_coef: 0.8804\n",
      "Epoch 50/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1201 - dice_coef: 0.8799\n",
      "Epoch 51/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1231 - dice_coef: 0.8769\n",
      "Epoch 52/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1100 - dice_coef: 0.8900\n",
      "Epoch 53/100\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.1106 - dice_coef: 0.8894\n",
      "Epoch 54/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1117 - dice_coef: 0.8883\n",
      "Epoch 55/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1143 - dice_coef: 0.8857\n",
      "Epoch 56/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1011 - dice_coef: 0.8989\n",
      "Epoch 57/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.1017 - dice_coef: 0.8983\n",
      "Epoch 58/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0947 - dice_coef: 0.9053\n",
      "Epoch 59/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0902 - dice_coef: 0.9098\n",
      "Epoch 60/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0870 - dice_coef: 0.9130\n",
      "Epoch 61/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0910 - dice_coef: 0.9090\n",
      "Epoch 62/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0837 - dice_coef: 0.9163\n",
      "Epoch 63/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0782 - dice_coef: 0.9218\n",
      "Epoch 64/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0871 - dice_coef: 0.9129\n",
      "Epoch 65/100\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0817 - dice_coef: 0.9183\n",
      "Epoch 66/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0815 - dice_coef: 0.9185\n",
      "Epoch 67/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0869 - dice_coef: 0.9131\n",
      "Epoch 68/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0887 - dice_coef: 0.9113\n",
      "Epoch 69/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0851 - dice_coef: 0.9149\n",
      "Epoch 70/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.0845 - dice_coef: 0.9155\n",
      "Epoch 71/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.0895 - dice_coef: 0.9105\n",
      "Epoch 72/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.0838 - dice_coef: 0.9162\n",
      "Epoch 73/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.0784 - dice_coef: 0.9216\n",
      "Epoch 74/100\n",
      "230/230 [==============================] - 5s 22ms/step - loss: 0.0820 - dice_coef: 0.9180\n",
      "Epoch 75/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0770 - dice_coef: 0.9230\n",
      "Epoch 76/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0873 - dice_coef: 0.9127\n",
      "Epoch 77/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0776 - dice_coef: 0.9224\n",
      "Epoch 78/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0715 - dice_coef: 0.9285\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0828 - dice_coef: 0.9172\n",
      "Epoch 80/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0821 - dice_coef: 0.9179\n",
      "Epoch 81/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0741 - dice_coef: 0.9259\n",
      "Epoch 82/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0724 - dice_coef: 0.9276\n",
      "Epoch 83/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0648 - dice_coef: 0.9352\n",
      "Epoch 84/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0618 - dice_coef: 0.9382\n",
      "Epoch 85/100\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0623 - dice_coef: 0.9377\n",
      "Epoch 86/100\n",
      "230/230 [==============================] - 6s 25ms/step - loss: 0.0616 - dice_coef: 0.9384\n",
      "Epoch 87/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0591 - dice_coef: 0.9409\n",
      "Epoch 88/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0594 - dice_coef: 0.9406\n",
      "Epoch 89/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0560 - dice_coef: 0.9440\n",
      "Epoch 90/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0561 - dice_coef: 0.9439\n",
      "Epoch 91/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0586 - dice_coef: 0.9414\n",
      "Epoch 92/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0580 - dice_coef: 0.9420\n",
      "Epoch 93/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0557 - dice_coef: 0.9443\n",
      "Epoch 94/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.0606 - dice_coef: 0.9394\n",
      "Epoch 95/100\n",
      "230/230 [==============================] - 6s 24ms/step - loss: 0.1022 - dice_coef: 0.8978\n",
      "Epoch 96/100\n",
      "230/230 [==============================] - 5s 22ms/step - loss: 0.0804 - dice_coef: 0.9196\n",
      "Epoch 97/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0939 - dice_coef: 0.9061\n",
      "Epoch 98/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0759 - dice_coef: 0.9241\n",
      "Epoch 99/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0674 - dice_coef: 0.9326\n",
      "Epoch 100/100\n",
      "230/230 [==============================] - 5s 21ms/step - loss: 0.0676 - dice_coef: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuroda-NotePC\\Anaconda3\\envs\\keras_gpu\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#from unet import UNet\n",
    "\n",
    "# ダイス係数を計算する関数\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return 2.0 * intersection / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "\n",
    "# ロス関数\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "# U-Netのトレーニングを実行する関数\n",
    "def train_unet():\n",
    "    # trainingDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "    X_train, file_names = load_X('trainingData' + os.sep + 'original')\n",
    "    # trainingDataフォルダ配下にleft_groundTruthフォルダを置いている\n",
    "    Y_train = load_Y('trainingData' + os.sep + 'segmentation')\n",
    "\n",
    "    # 入力はBGR3チャンネル\n",
    "    input_channel_count = 3\n",
    "    # 出力はグレースケール1チャンネル\n",
    "    output_channel_count = 1\n",
    "    # 一番初めのConvolutionフィルタ枚数は64\n",
    "    first_layer_filter_count = 64\n",
    "    # U-Netの生成\n",
    "    network = UNet(input_channel_count, output_channel_count, first_layer_filter_count)\n",
    "    model = network.get_model()\n",
    "    model.compile(loss=dice_coef_loss, optimizer=Adam(), metrics=[dice_coef])\n",
    "\n",
    "    BATCH_SIZE = 12\n",
    "    NUM_EPOCH = 100\n",
    "    history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, verbose=1)\n",
    "    model.save_weights('unet_weights.h5')\n",
    "\n",
    "\n",
    "# 学習後のU-Netによる予測を行う関数\n",
    "def predict():\n",
    "    import cv2\n",
    "\n",
    "    # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "    X_test, file_names = load_X('testData' + os.sep + 'original')\n",
    "\n",
    "    input_channel_count = 3\n",
    "    output_channel_count = 1\n",
    "    first_layer_filter_count = 64\n",
    "    network = UNet(input_channel_count, output_channel_count, first_layer_filter_count)\n",
    "    model = network.get_model()\n",
    "    model.load_weights('unet_weights.h5')\n",
    "    BATCH_SIZE = 12\n",
    "    Y_pred = model.predict(X_test, BATCH_SIZE)\n",
    "\n",
    "    for i, y in enumerate(Y_pred):\n",
    "        # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "        img = cv2.imread('testData' + os.sep + 'original' + os.sep + file_names[i])\n",
    "        y = cv2.resize(y, (img.shape[1], img.shape[0]))\n",
    "        cv2.imwrite('prediction' + os.sep + 'prediction' + str(i) + '.png', denormalize_y(y))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_unet()\n",
    "    predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_gpu",
   "language": "python",
   "name": "keras_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
